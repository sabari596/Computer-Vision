{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbfb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands module and drawing utilities\n",
    "mpHands = mp.solutions.hands\n",
    "drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open the default camera (0 = main webcam)\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "# Configure MediaPipe Hands detection model\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,          # Real-time video mode\n",
    "    max_num_hands=2,                  # Detect up to 2 hands\n",
    "    min_detection_confidence=0.5,     # Confidence threshold for detection\n",
    "    min_tracking_confidence=0.5       # Confidence threshold for tracking\n",
    ")\n",
    "\n",
    "# Landmark indices of all fingertips\n",
    "finger_tips = [4, 8, 12, 16, 20]\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    success, frame = cam.read()\n",
    "    if not success:\n",
    "        print(\"Camera not detected\")\n",
    "        continue\n",
    "\n",
    "    # Mirror the image for natural viewing\n",
    "    frame = cv.flip(frame, 1)\n",
    "\n",
    "    # MediaPipe processes only RGB images (OpenCV uses BGR)\n",
    "    frameRGB = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect hands and landmarks in the image\n",
    "    results = hands.process(frameRGB)\n",
    "\n",
    "    # If at least one hand is detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Loop through each detected hand\n",
    "        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "\n",
    "            # Draw hand landmarks & connections on the image\n",
    "            drawing.draw_landmarks(frame, hand_landmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Store all landmark coordinates (converted to pixel positions)\n",
    "            lm_list = []\n",
    "            h, w, c = frame.shape\n",
    "            for id, lm in enumerate(hand_landmarks.landmark):\n",
    "                lm_list.append((id, lm.x * w, lm.y * h))\n",
    "\n",
    "            # Get which hand it is (\"Left\" or \"Right\")\n",
    "            hand_label = results.multi_handedness[i].classification[0].label\n",
    "\n",
    "            fingers_up = 0  # Counter for raised fingers\n",
    "\n",
    "            # ---------------- THUMB ----------------\n",
    "            # Thumb uses X-axis comparison (left-right movement)\n",
    "            thumb_tip_x = lm_list[4][1]     # Landmark 4: thumb tip\n",
    "            thumb_joint_x = lm_list[3][1]   # Landmark 3: thumb lower joint\n",
    "\n",
    "            if hand_label == \"Right\":\n",
    "                # For right hand: thumb extends leftwards\n",
    "                if thumb_tip_x < thumb_joint_x:\n",
    "                    fingers_up += 1\n",
    "            else:  # Left hand\n",
    "                # For left hand: thumb extends rightwards\n",
    "                if thumb_tip_x > thumb_joint_x:\n",
    "                    fingers_up += 1\n",
    "\n",
    "            # ---------------- OTHER FOUR FINGERS ----------------\n",
    "            # Compare Y-axis (up-down movement)\n",
    "            for tip_id in [8, 12, 16, 20]:\n",
    "                # A finger is considered \"up\" if tip is above the joint\n",
    "                if lm_list[tip_id][2] < lm_list[tip_id - 2][2]:\n",
    "                    fingers_up += 1\n",
    "\n",
    "            # Display the result on the screen\n",
    "            cv.putText(frame, f\"{hand_label} Hand: {fingers_up}\",\n",
    "                       (10, 120 + 40 * i),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 1.2,\n",
    "                       (255, 0, 0), 3)\n",
    "\n",
    "    # Show processed video frame\n",
    "    cv.imshow(\"Finger Counting\", frame)\n",
    "\n",
    "    # Exit loop when 'q' is pressed\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release camera and close all OpenCV windows\n",
    "cam.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530321ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv_env)",
   "language": "python",
   "name": "cv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
